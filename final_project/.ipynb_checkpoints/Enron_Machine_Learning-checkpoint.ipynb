{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to load in the email and financial data with all of the features. I will convert the dictionary into a pandas dataframe for easier cleaning and manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tester\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\". \n",
    "payment_data = ['salary',\n",
    "                'bonus',\n",
    "                'long_term_incentive',\n",
    "                'deferred_income',\n",
    "                'deferral_payments',\n",
    "                'loan_advances',\n",
    "                'other',\n",
    "                'expenses',                \n",
    "                'director_fees', \n",
    "                'total_payments']\n",
    "\n",
    "stock_data = ['exercised_stock_options',\n",
    "              'restricted_stock',\n",
    "              'restricted_stock_deferred',\n",
    "              'total_stock_value']\n",
    "\n",
    "email_data = ['to_messages',\n",
    "              'from_messages',\n",
    "              'from_poi_to_this_person',\n",
    "              'from_this_person_to_poi',\n",
    "              'shared_receipt_with_poi']\n",
    "              \n",
    "              \n",
    "features_list = ['poi'] + payment_data + stock_data + email_data\n",
    "                 # You will need to use more features\n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "\n",
    "df = pd.DataFrame.from_dict(data_dict, orient='index')\n",
    "df = df.replace('NaN', np.nan)\n",
    "df = df[features_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 146 entries, ALLEN PHILLIP K to YEAP SOON\n",
      "Data columns (total 20 columns):\n",
      "poi                          146 non-null bool\n",
      "salary                       95 non-null float64\n",
      "bonus                        82 non-null float64\n",
      "long_term_incentive          66 non-null float64\n",
      "deferred_income              49 non-null float64\n",
      "deferral_payments            39 non-null float64\n",
      "loan_advances                4 non-null float64\n",
      "other                        93 non-null float64\n",
      "expenses                     95 non-null float64\n",
      "director_fees                17 non-null float64\n",
      "total_payments               125 non-null float64\n",
      "exercised_stock_options      102 non-null float64\n",
      "restricted_stock             110 non-null float64\n",
      "restricted_stock_deferred    18 non-null float64\n",
      "total_stock_value            126 non-null float64\n",
      "to_messages                  86 non-null float64\n",
      "from_messages                86 non-null float64\n",
      "from_poi_to_this_person      86 non-null float64\n",
      "from_this_person_to_poi      86 non-null float64\n",
      "shared_receipt_with_poi      86 non-null float64\n",
      "dtypes: bool(1), float64(19)\n",
      "memory usage: 23.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to convert all of the data types to floating point numbers except for the poi column which can remain as a boolean. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the official documentation for the dataset, values of NaN in the financial dataset represent 0 and not unknown quantities. However, for the email data, NaNs stand for unknown information. Therefore, I will replace any financial data that is NaN with 0 but will fill in the NaNs for the email data with the median of the column grouped by person of interest. In other words, if a person has a NaN value for 'to_messages', and they are a person of interest, I will fill in that value with the median value of 'to_messages' for a person of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[payment_data] = df[payment_data].fillna(0)\n",
    "df[stock_data] = df[stock_data].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imp = Imputer(missing_values='NaN', strategy = 'mean', axis=0)\n",
    "\n",
    "df_poi = df[df['poi'] == True]\n",
    "df_nonpoi = df[df['poi']==False]\n",
    "\n",
    "df_poi.ix[:, email_data] = imp.fit_transform(df_poi.ix[:,email_data])\n",
    "df_nonpoi.ix[:, email_data] = imp.fit_transform(df_nonpoi.ix[:,email_data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df_poi.append(df_nonpoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One simple way to check for outliers/incorrect data is to add up all of the payment related columns for each person and see if that is equal to the total payment recorded for the individual. I can also do the same for stock payments. If the data was entered by hand, I would expect that there would be at least a few errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poi</th>\n",
       "      <th>salary</th>\n",
       "      <th>bonus</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>other</th>\n",
       "      <th>expenses</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BELFER ROBERT</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-102500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3285.0</td>\n",
       "      <td>102500.0</td>\n",
       "      <td>3285.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44093.0</td>\n",
       "      <td>-44093.0</td>\n",
       "      <td>2007.111111</td>\n",
       "      <td>668.763889</td>\n",
       "      <td>58.5</td>\n",
       "      <td>36.277778</td>\n",
       "      <td>1058.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BHATNAGAR SANJAY</th>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137864.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137864.0</td>\n",
       "      <td>15456290.0</td>\n",
       "      <td>2604490.0</td>\n",
       "      <td>-2604490.0</td>\n",
       "      <td>15456290.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>523.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>463.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    poi  salary  bonus  long_term_incentive  deferred_income  \\\n",
       "BELFER ROBERT     False     0.0    0.0                  0.0              0.0   \n",
       "BHATNAGAR SANJAY  False     0.0    0.0                  0.0              0.0   \n",
       "\n",
       "                  deferral_payments  loan_advances     other  expenses  \\\n",
       "BELFER ROBERT             -102500.0            0.0       0.0       0.0   \n",
       "BHATNAGAR SANJAY                0.0            0.0  137864.0       0.0   \n",
       "\n",
       "                  director_fees  total_payments  exercised_stock_options  \\\n",
       "BELFER ROBERT            3285.0        102500.0                   3285.0   \n",
       "BHATNAGAR SANJAY       137864.0      15456290.0                2604490.0   \n",
       "\n",
       "                  restricted_stock  restricted_stock_deferred  \\\n",
       "BELFER ROBERT                  0.0                    44093.0   \n",
       "BHATNAGAR SANJAY        -2604490.0                 15456290.0   \n",
       "\n",
       "                  total_stock_value  to_messages  from_messages  \\\n",
       "BELFER ROBERT              -44093.0  2007.111111     668.763889   \n",
       "BHATNAGAR SANJAY                0.0   523.000000      29.000000   \n",
       "\n",
       "                  from_poi_to_this_person  from_this_person_to_poi  \\\n",
       "BELFER ROBERT                        58.5                36.277778   \n",
       "BHATNAGAR SANJAY                      0.0                 1.000000   \n",
       "\n",
       "                  shared_receipt_with_poi  \n",
       "BELFER ROBERT                 1058.527778  \n",
       "BHATNAGAR SANJAY               463.000000  "
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[payment_data[:-1]].sum(axis='columns') != df['total_payments']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to correct the discrepancies which most likely arise from incorrect data entry, I can use the official financial data gathered by FineLaw and [available through Udacity's GitHub](https://github.com/udacity/ud120-projects/blob/master/final_project/enron61702insiderpay.pdf). \n",
    "For Robert Belfer, the financial data has been shifted one column to the right, and for Sanjay Bhatnagar, the financial data has been shifted one column to the left. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Retrieve the incorrect data for Belfer\n",
    "belfer_financial = df.ix['BELFER ROBERT', 1:15].tolist()\n",
    "# Delete the first element to shift left and add on a 0 to end as indicated in financial data\n",
    "belfer_financial.pop(0)\n",
    "belfer_financial.append(0)\n",
    "# Reinsert corrected data\n",
    "df.ix['BELFER ROBERT', 1:15] = belfer_financial\n",
    "\n",
    "# Retrieve the incorrect data for Bhatnagar\n",
    "bhatnagar_financial = df.ix['BHATNAGAR SANJAY', 1:15].tolist()\n",
    "# Delete the last element to shift right and add on a 0 to beginning\n",
    "bhatnagar_financial.pop(-1)\n",
    "bhatnagar_financial = [0] + bhatnagar_financial\n",
    "# Reinsert corrected data\n",
    "df.ix['BHATNAGAR SANJAY', 1:15] = bhatnagar_financial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df[payment_data[:-1]].sum(axis='columns') != df['total_payments']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df[stock_data[:-1]].sum(axis='columns') != df['total_stock_value']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correcting the shifted financial data eliminated two errors. However, there may still be outliers in the dataset that need to be removed. Looking through the official financial PDF, I can see that I need to remove 'TOTAL' as it is entered as an individual (even though this is correct data, it is not a person and will be of no value when trying to identify persons of interest). Likewise, there is an entry for 'THE TRAVEL AGENCY IN THE PARK', which according to the documentation was a company co-owned by Enron's former Chairman's sister and is clearly not an individual that should be included in the dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(axis=0, labels=['TOTAL','THE TRAVEL AGENCY IN THE PARK'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can now look for individual outliers. However, I will need to be conservative in terms of removing the outliers because the dataset is rather small for machine learning in the first place. Moreover, the outliers might actually be important as they could represent patterns in the data that would aid in the identification of persons of interest. Using the [official definition of a mild outlier](http://www.itl.nist.gov/div898/handbook/prc/section1/prc16.htm) as either -1.5 times the Interquartile Range (IQR) below the 1st interquartile or +1.5 times the IQR above the 3rd quartile, I will count the number of columns in which each indivdual is an outlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IQR = df.quantile(q=0.75) - df.quantile(q=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first_quartile = df.quantile(q=0.25)\n",
    "third_quartile = df.quantile(q=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LAY KENNETH L         15\n",
       "FREVERT MARK A        12\n",
       "BELDEN TIMOTHY N       9\n",
       "SKILLING JEFFREY K     9\n",
       "BAXTER JOHN C          8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers = df[(df>(third_quartile + 1.5*IQR) ) | (df<(first_quartile - 1.5*IQR) )].count(axis=1)\n",
    "outliers.sort_values(axis=0, ascending=False, inplace=True)\n",
    "outliers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this point, I need to do some research before blinding deleting outliers, especially if the outliers are persons of interest. Based on the small number of persons of interest initially in the dataset, I will choose to not remove any individuals who are persons are interest regardless of the number of outliers they may have. An outlier could be a sign of fradulent activity, as it could be evidence that someone is laundering illegal funds through the company payroll or maybe an accomplish is being paid to remain quiet about the activity. I will examine the top seven outliers which is around 5% of the total dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outliers = outliers[:7].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LAY KENNETH L',\n",
       " 'FREVERT MARK A',\n",
       " 'BELDEN TIMOTHY N',\n",
       " 'SKILLING JEFFREY K',\n",
       " 'BAXTER JOHN C',\n",
       " 'LAVORATO JOHN J',\n",
       " 'DELAINEY DAVID W']"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_outliers = df.ix[outliers, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poi</th>\n",
       "      <th>salary</th>\n",
       "      <th>bonus</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>loan_advances</th>\n",
       "      <th>other</th>\n",
       "      <th>expenses</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>total_stock_value</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LAY KENNETH L</th>\n",
       "      <td>True</td>\n",
       "      <td>1072321.0</td>\n",
       "      <td>7000000.0</td>\n",
       "      <td>3600000.0</td>\n",
       "      <td>-300000.0</td>\n",
       "      <td>202911.0</td>\n",
       "      <td>81525000.0</td>\n",
       "      <td>10359729.0</td>\n",
       "      <td>99832.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103559793.0</td>\n",
       "      <td>34348384.0</td>\n",
       "      <td>14761694.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49110078.0</td>\n",
       "      <td>4273.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>123.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>2411.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FREVERT MARK A</th>\n",
       "      <td>False</td>\n",
       "      <td>1060932.0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>1617011.0</td>\n",
       "      <td>-3367011.0</td>\n",
       "      <td>6426990.0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>7427621.0</td>\n",
       "      <td>86987.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17252530.0</td>\n",
       "      <td>10433518.0</td>\n",
       "      <td>4188667.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14622185.0</td>\n",
       "      <td>3275.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>242.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2979.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BELDEN TIMOTHY N</th>\n",
       "      <td>True</td>\n",
       "      <td>213999.0</td>\n",
       "      <td>5249999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2334434.0</td>\n",
       "      <td>2144013.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>210698.0</td>\n",
       "      <td>17355.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5501630.0</td>\n",
       "      <td>953136.0</td>\n",
       "      <td>157569.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1110705.0</td>\n",
       "      <td>7991.000000</td>\n",
       "      <td>484.000000</td>\n",
       "      <td>228.0</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>5521.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SKILLING JEFFREY K</th>\n",
       "      <td>True</td>\n",
       "      <td>1111258.0</td>\n",
       "      <td>5600000.0</td>\n",
       "      <td>1920000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22122.0</td>\n",
       "      <td>29336.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8682716.0</td>\n",
       "      <td>19250000.0</td>\n",
       "      <td>6843672.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26093672.0</td>\n",
       "      <td>3627.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>88.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2042.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAXTER JOHN C</th>\n",
       "      <td>False</td>\n",
       "      <td>267102.0</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>1586055.0</td>\n",
       "      <td>-1386055.0</td>\n",
       "      <td>1295738.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2660303.0</td>\n",
       "      <td>11200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5634343.0</td>\n",
       "      <td>6680544.0</td>\n",
       "      <td>3942714.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10623258.0</td>\n",
       "      <td>2007.111111</td>\n",
       "      <td>668.763889</td>\n",
       "      <td>58.5</td>\n",
       "      <td>36.277778</td>\n",
       "      <td>1058.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAVORATO JOHN J</th>\n",
       "      <td>False</td>\n",
       "      <td>339288.0</td>\n",
       "      <td>8000000.0</td>\n",
       "      <td>2035380.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1552.0</td>\n",
       "      <td>49537.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10425757.0</td>\n",
       "      <td>4158995.0</td>\n",
       "      <td>1008149.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5167144.0</td>\n",
       "      <td>7259.000000</td>\n",
       "      <td>2585.000000</td>\n",
       "      <td>528.0</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>3962.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DELAINEY DAVID W</th>\n",
       "      <td>True</td>\n",
       "      <td>365163.0</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>1294981.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1661.0</td>\n",
       "      <td>86174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4747979.0</td>\n",
       "      <td>2291113.0</td>\n",
       "      <td>1323148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3614261.0</td>\n",
       "      <td>3093.000000</td>\n",
       "      <td>3069.000000</td>\n",
       "      <td>66.0</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>2097.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      poi     salary      bonus  long_term_incentive  \\\n",
       "LAY KENNETH L        True  1072321.0  7000000.0            3600000.0   \n",
       "FREVERT MARK A      False  1060932.0  2000000.0            1617011.0   \n",
       "BELDEN TIMOTHY N     True   213999.0  5249999.0                  0.0   \n",
       "SKILLING JEFFREY K   True  1111258.0  5600000.0            1920000.0   \n",
       "BAXTER JOHN C       False   267102.0  1200000.0            1586055.0   \n",
       "LAVORATO JOHN J     False   339288.0  8000000.0            2035380.0   \n",
       "DELAINEY DAVID W     True   365163.0  3000000.0            1294981.0   \n",
       "\n",
       "                    deferred_income  deferral_payments  loan_advances  \\\n",
       "LAY KENNETH L             -300000.0           202911.0     81525000.0   \n",
       "FREVERT MARK A           -3367011.0          6426990.0      2000000.0   \n",
       "BELDEN TIMOTHY N         -2334434.0          2144013.0            0.0   \n",
       "SKILLING JEFFREY K              0.0                0.0            0.0   \n",
       "BAXTER JOHN C            -1386055.0          1295738.0            0.0   \n",
       "LAVORATO JOHN J                 0.0                0.0            0.0   \n",
       "DELAINEY DAVID W                0.0                0.0            0.0   \n",
       "\n",
       "                         other  expenses  director_fees  total_payments  \\\n",
       "LAY KENNETH L       10359729.0   99832.0            0.0     103559793.0   \n",
       "FREVERT MARK A       7427621.0   86987.0            0.0      17252530.0   \n",
       "BELDEN TIMOTHY N      210698.0   17355.0            0.0       5501630.0   \n",
       "SKILLING JEFFREY K     22122.0   29336.0            0.0       8682716.0   \n",
       "BAXTER JOHN C        2660303.0   11200.0            0.0       5634343.0   \n",
       "LAVORATO JOHN J         1552.0   49537.0            0.0      10425757.0   \n",
       "DELAINEY DAVID W        1661.0   86174.0            0.0       4747979.0   \n",
       "\n",
       "                    exercised_stock_options  restricted_stock  \\\n",
       "LAY KENNETH L                    34348384.0        14761694.0   \n",
       "FREVERT MARK A                   10433518.0         4188667.0   \n",
       "BELDEN TIMOTHY N                   953136.0          157569.0   \n",
       "SKILLING JEFFREY K               19250000.0         6843672.0   \n",
       "BAXTER JOHN C                     6680544.0         3942714.0   \n",
       "LAVORATO JOHN J                   4158995.0         1008149.0   \n",
       "DELAINEY DAVID W                  2291113.0         1323148.0   \n",
       "\n",
       "                    restricted_stock_deferred  total_stock_value  to_messages  \\\n",
       "LAY KENNETH L                             0.0         49110078.0  4273.000000   \n",
       "FREVERT MARK A                            0.0         14622185.0  3275.000000   \n",
       "BELDEN TIMOTHY N                          0.0          1110705.0  7991.000000   \n",
       "SKILLING JEFFREY K                        0.0         26093672.0  3627.000000   \n",
       "BAXTER JOHN C                             0.0         10623258.0  2007.111111   \n",
       "LAVORATO JOHN J                           0.0          5167144.0  7259.000000   \n",
       "DELAINEY DAVID W                          0.0          3614261.0  3093.000000   \n",
       "\n",
       "                    from_messages  from_poi_to_this_person  \\\n",
       "LAY KENNETH L           36.000000                    123.0   \n",
       "FREVERT MARK A          21.000000                    242.0   \n",
       "BELDEN TIMOTHY N       484.000000                    228.0   \n",
       "SKILLING JEFFREY K     108.000000                     88.0   \n",
       "BAXTER JOHN C          668.763889                     58.5   \n",
       "LAVORATO JOHN J       2585.000000                    528.0   \n",
       "DELAINEY DAVID W      3069.000000                     66.0   \n",
       "\n",
       "                    from_this_person_to_poi  shared_receipt_with_poi  \n",
       "LAY KENNETH L                     16.000000              2411.000000  \n",
       "FREVERT MARK A                     6.000000              2979.000000  \n",
       "BELDEN TIMOTHY N                 108.000000              5521.000000  \n",
       "SKILLING JEFFREY K                30.000000              2042.000000  \n",
       "BAXTER JOHN C                     36.277778              1058.527778  \n",
       "LAVORATO JOHN J                  411.000000              3962.000000  \n",
       "DELAINEY DAVID W                 609.000000              2097.000000  "
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few considerations to make here:\n",
    "1. Kenneth Lay, [the CEO of Enron from 1986-2001](http://www.biography.com/people/kenneth-lay-234611), presided over many of the illegal business activites and hence is one of the most important persons of interest. \n",
    "2. Mark Frevert served as chief executive of [Enron Europe from 1986-2000 and was appointed as chairman of Enron in 2001](http://www.risk.net/risk-management/2123422/ten-years-after-its-collapse-enron-lives-energy-markets). He was a major player in the firm, although not a person of interest. I believe that he is not representative of the average employee at Enron during this time because of his substantial compensation and will remove him from the dataset. \n",
    "3. Timothy Belden was the [former head of trading for Enron](http://articles.latimes.com/2007/feb/15/business/fi-enron15) who developed the strategy to illegally raise energy prices in California. He was a person of interest and will definitely remain in the dataset. \n",
    "4. Jeffrey Skilling [replaced Kenneth Lay as CEO of Enron in 2001 and orchestrated much of the fraud](http://www.biography.com/people/jeffrey-skilling-235386) that destroyed Enron. As a person of interest, he will remain in the dataset. \n",
    "5. John Baxter was a former vice Enron vice chairman and [died of an apparent self-inflicted gunshot](https://www.wsws.org/en/articles/2002/01/enro-j28.html) before he was able to testify against other Enron executives. I will remove him from the dataset as he is not a person of interest. \n",
    "6. John Lavorato was a top executive in the energy-trading branch of Enron and received large bonuses to [keep him from leaving Enron](http://www.nytimes.com/2002/06/18/business/officials-got-a-windfall-before-enron-s-collapse.html). As he was not a person of interest, and the large bonus ended up skewing his total pay towards the top of the range, I think it would be appropriate to remove him from the dataset. \n",
    "4. Lawrence Whalley [served as the president of Enron](http://www.corpwatch.org/article.php?id=13194) and fired Andrew Fastow once it was apparent the severity of Enron's situation. He was investigated thoroughly but not identified as a person of interest and therefore will be removed from the dataset.  \n",
    "\n",
    "Total, that is four people to remove from the dataset. I believe these removals are justified primarily because none of these individuals were persons of interest and they all were upper-level executives with pay levels far above the average employee. I hesitate to remove any samples from the data, but I believe that removing these individuals will improve the quality of the classifier. I can try with and without removing these individuals and measure the accuracy, precision, and recall of the classifier to determine if my choice was justified.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.drop(axis=0, labels=['FREVERT MARK A', 'LAVORATO JOHN J', 'WHALLEY LAWRENCE G', 'BAXTER JOHN C'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    122\n",
       "True      18\n",
       "Name: poi, dtype: int64"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['poi'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1150"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df==0].count().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a total of 2800 observations of financial and email data in the set now that the data cleaning has been finished. Of these, __1150 or 41%__ are 0 financial values. There are 18 persons of interest, comprising __12.9%__ of the individuals. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to begin training some classifiers with default parameters in order to identify existing features that are most predicative of persons of interest. After that, if the classifier performance is low, I will try and devise additional features and then fine-tune the algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "\tAccuracy: 0.86429\tPrecision: 0.52941\tRecall: 0.45000\tF1: 0.48649\tF2: 0.46392\n",
      "\tTotal predictions:  140\tTrue positives:    9\tFalse positives:    8\tFalse negatives:   11\tTrue negatives:  112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df.ix[:,1:] = scale(df.ix[:,1:])\n",
    "data_dict = df.to_dict(orient='index')\n",
    "\n",
    "my_dataset = data_dict\n",
    "data = featureFormat(my_dataset, features_list, sort_keys=True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "# Create the classifier, GaussianNB has no parameters to tune\n",
    "clf = DecisionTreeClassifier(criterion='entropy')\n",
    "dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "clf = tester.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
